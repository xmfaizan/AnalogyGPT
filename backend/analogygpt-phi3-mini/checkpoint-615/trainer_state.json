{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 615,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01628001628001628,
      "grad_norm": 1.887290120124817,
      "learning_rate": 9e-06,
      "loss": 3.1492,
      "step": 10
    },
    {
      "epoch": 0.03256003256003256,
      "grad_norm": 1.9540897607803345,
      "learning_rate": 1.9e-05,
      "loss": 2.9923,
      "step": 20
    },
    {
      "epoch": 0.04884004884004884,
      "grad_norm": 0.7482802867889404,
      "learning_rate": 2.9e-05,
      "loss": 2.6187,
      "step": 30
    },
    {
      "epoch": 0.06512006512006512,
      "grad_norm": 0.9587072730064392,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 2.546,
      "step": 40
    },
    {
      "epoch": 0.0814000814000814,
      "grad_norm": 0.9035333395004272,
      "learning_rate": 4.9e-05,
      "loss": 2.1909,
      "step": 50
    },
    {
      "epoch": 0.09768009768009768,
      "grad_norm": 0.8544525504112244,
      "learning_rate": 4.961864406779661e-05,
      "loss": 1.9077,
      "step": 60
    },
    {
      "epoch": 0.11396011396011396,
      "grad_norm": 0.924026608467102,
      "learning_rate": 4.919491525423729e-05,
      "loss": 1.5132,
      "step": 70
    },
    {
      "epoch": 0.13024013024013023,
      "grad_norm": 1.056766390800476,
      "learning_rate": 4.88135593220339e-05,
      "loss": 1.1531,
      "step": 80
    },
    {
      "epoch": 0.14652014652014653,
      "grad_norm": 1.1141852140426636,
      "learning_rate": 4.8389830508474574e-05,
      "loss": 1.0166,
      "step": 90
    },
    {
      "epoch": 0.1628001628001628,
      "grad_norm": 0.8041523098945618,
      "learning_rate": 4.796610169491525e-05,
      "loss": 0.8734,
      "step": 100
    },
    {
      "epoch": 0.1790801790801791,
      "grad_norm": 0.7326760292053223,
      "learning_rate": 4.754237288135593e-05,
      "loss": 0.7764,
      "step": 110
    },
    {
      "epoch": 0.19536019536019536,
      "grad_norm": 0.5767306089401245,
      "learning_rate": 4.711864406779661e-05,
      "loss": 0.8504,
      "step": 120
    },
    {
      "epoch": 0.21164021164021163,
      "grad_norm": 0.855254590511322,
      "learning_rate": 4.669491525423729e-05,
      "loss": 0.7419,
      "step": 130
    },
    {
      "epoch": 0.22792022792022792,
      "grad_norm": 0.993162214756012,
      "learning_rate": 4.6271186440677964e-05,
      "loss": 0.7147,
      "step": 140
    },
    {
      "epoch": 0.2442002442002442,
      "grad_norm": 0.8096955418586731,
      "learning_rate": 4.5847457627118644e-05,
      "loss": 0.7442,
      "step": 150
    },
    {
      "epoch": 0.26048026048026046,
      "grad_norm": 0.7697708010673523,
      "learning_rate": 4.542372881355932e-05,
      "loss": 0.7421,
      "step": 160
    },
    {
      "epoch": 0.27676027676027676,
      "grad_norm": 0.7750405669212341,
      "learning_rate": 4.5e-05,
      "loss": 0.7419,
      "step": 170
    },
    {
      "epoch": 0.29304029304029305,
      "grad_norm": 0.7274835705757141,
      "learning_rate": 4.457627118644068e-05,
      "loss": 0.7048,
      "step": 180
    },
    {
      "epoch": 0.3093203093203093,
      "grad_norm": 0.6769528985023499,
      "learning_rate": 4.4152542372881355e-05,
      "loss": 0.723,
      "step": 190
    },
    {
      "epoch": 0.3256003256003256,
      "grad_norm": 0.7688562870025635,
      "learning_rate": 4.3728813559322035e-05,
      "loss": 0.6998,
      "step": 200
    },
    {
      "epoch": 0.3418803418803419,
      "grad_norm": 0.7896013855934143,
      "learning_rate": 4.3305084745762714e-05,
      "loss": 0.7142,
      "step": 210
    },
    {
      "epoch": 0.3581603581603582,
      "grad_norm": 1.0522710084915161,
      "learning_rate": 4.2881355932203394e-05,
      "loss": 0.6904,
      "step": 220
    },
    {
      "epoch": 0.3744403744403744,
      "grad_norm": 0.9165351390838623,
      "learning_rate": 4.245762711864407e-05,
      "loss": 0.6874,
      "step": 230
    },
    {
      "epoch": 0.3907203907203907,
      "grad_norm": 0.8769110441207886,
      "learning_rate": 4.2033898305084746e-05,
      "loss": 0.7104,
      "step": 240
    },
    {
      "epoch": 0.407000407000407,
      "grad_norm": 0.8183981776237488,
      "learning_rate": 4.1610169491525425e-05,
      "loss": 0.6516,
      "step": 250
    },
    {
      "epoch": 0.42328042328042326,
      "grad_norm": 1.1240686178207397,
      "learning_rate": 4.1186440677966105e-05,
      "loss": 0.6828,
      "step": 260
    },
    {
      "epoch": 0.43956043956043955,
      "grad_norm": 0.8589078783988953,
      "learning_rate": 4.0762711864406784e-05,
      "loss": 0.6783,
      "step": 270
    },
    {
      "epoch": 0.45584045584045585,
      "grad_norm": 0.8516453504562378,
      "learning_rate": 4.0338983050847464e-05,
      "loss": 0.6743,
      "step": 280
    },
    {
      "epoch": 0.47212047212047215,
      "grad_norm": 0.7236848473548889,
      "learning_rate": 3.9915254237288136e-05,
      "loss": 0.6825,
      "step": 290
    },
    {
      "epoch": 0.4884004884004884,
      "grad_norm": 0.855140745639801,
      "learning_rate": 3.9491525423728816e-05,
      "loss": 0.671,
      "step": 300
    },
    {
      "epoch": 0.5046805046805046,
      "grad_norm": 0.8440850973129272,
      "learning_rate": 3.9067796610169495e-05,
      "loss": 0.6776,
      "step": 310
    },
    {
      "epoch": 0.5209605209605209,
      "grad_norm": 0.8390825390815735,
      "learning_rate": 3.8644067796610175e-05,
      "loss": 0.655,
      "step": 320
    },
    {
      "epoch": 0.5372405372405372,
      "grad_norm": 1.0086815357208252,
      "learning_rate": 3.8220338983050854e-05,
      "loss": 0.6647,
      "step": 330
    },
    {
      "epoch": 0.5535205535205535,
      "grad_norm": 0.7752877473831177,
      "learning_rate": 3.779661016949153e-05,
      "loss": 0.6534,
      "step": 340
    },
    {
      "epoch": 0.5698005698005698,
      "grad_norm": 0.9149221777915955,
      "learning_rate": 3.737288135593221e-05,
      "loss": 0.6938,
      "step": 350
    },
    {
      "epoch": 0.5860805860805861,
      "grad_norm": 0.8430819511413574,
      "learning_rate": 3.6949152542372886e-05,
      "loss": 0.6901,
      "step": 360
    },
    {
      "epoch": 0.6023606023606024,
      "grad_norm": 1.1142338514328003,
      "learning_rate": 3.6525423728813566e-05,
      "loss": 0.6709,
      "step": 370
    },
    {
      "epoch": 0.6186406186406186,
      "grad_norm": 0.8852651715278625,
      "learning_rate": 3.610169491525424e-05,
      "loss": 0.6449,
      "step": 380
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 0.994490921497345,
      "learning_rate": 3.567796610169492e-05,
      "loss": 0.7045,
      "step": 390
    },
    {
      "epoch": 0.6512006512006512,
      "grad_norm": 1.0016900300979614,
      "learning_rate": 3.52542372881356e-05,
      "loss": 0.6583,
      "step": 400
    },
    {
      "epoch": 0.6674806674806675,
      "grad_norm": 0.8443682789802551,
      "learning_rate": 3.483050847457627e-05,
      "loss": 0.6084,
      "step": 410
    },
    {
      "epoch": 0.6837606837606838,
      "grad_norm": 0.7933271527290344,
      "learning_rate": 3.440677966101695e-05,
      "loss": 0.6708,
      "step": 420
    },
    {
      "epoch": 0.7000407000407001,
      "grad_norm": 0.9349954724311829,
      "learning_rate": 3.398305084745763e-05,
      "loss": 0.6282,
      "step": 430
    },
    {
      "epoch": 0.7163207163207164,
      "grad_norm": 0.8797197341918945,
      "learning_rate": 3.35593220338983e-05,
      "loss": 0.6602,
      "step": 440
    },
    {
      "epoch": 0.7326007326007326,
      "grad_norm": 1.1528881788253784,
      "learning_rate": 3.313559322033898e-05,
      "loss": 0.6495,
      "step": 450
    },
    {
      "epoch": 0.7488807488807488,
      "grad_norm": 0.8779690861701965,
      "learning_rate": 3.271186440677966e-05,
      "loss": 0.6176,
      "step": 460
    },
    {
      "epoch": 0.7651607651607651,
      "grad_norm": 0.9756469130516052,
      "learning_rate": 3.228813559322034e-05,
      "loss": 0.6637,
      "step": 470
    },
    {
      "epoch": 0.7814407814407814,
      "grad_norm": 1.074717402458191,
      "learning_rate": 3.186440677966101e-05,
      "loss": 0.6784,
      "step": 480
    },
    {
      "epoch": 0.7977207977207977,
      "grad_norm": 0.9332597851753235,
      "learning_rate": 3.144067796610169e-05,
      "loss": 0.6646,
      "step": 490
    },
    {
      "epoch": 0.814000814000814,
      "grad_norm": 0.9236867427825928,
      "learning_rate": 3.101694915254237e-05,
      "loss": 0.6685,
      "step": 500
    },
    {
      "epoch": 0.8302808302808303,
      "grad_norm": 0.8163477778434753,
      "learning_rate": 3.059322033898305e-05,
      "loss": 0.6365,
      "step": 510
    },
    {
      "epoch": 0.8465608465608465,
      "grad_norm": 0.8803297281265259,
      "learning_rate": 3.016949152542373e-05,
      "loss": 0.6156,
      "step": 520
    },
    {
      "epoch": 0.8628408628408628,
      "grad_norm": 0.9088124632835388,
      "learning_rate": 2.9745762711864407e-05,
      "loss": 0.5982,
      "step": 530
    },
    {
      "epoch": 0.8791208791208791,
      "grad_norm": 0.8476722240447998,
      "learning_rate": 2.9322033898305083e-05,
      "loss": 0.6489,
      "step": 540
    },
    {
      "epoch": 0.8954008954008954,
      "grad_norm": 0.967504620552063,
      "learning_rate": 2.8898305084745763e-05,
      "loss": 0.625,
      "step": 550
    },
    {
      "epoch": 0.9116809116809117,
      "grad_norm": 0.7797608375549316,
      "learning_rate": 2.8474576271186442e-05,
      "loss": 0.6079,
      "step": 560
    },
    {
      "epoch": 0.927960927960928,
      "grad_norm": 1.1280207633972168,
      "learning_rate": 2.8050847457627122e-05,
      "loss": 0.6495,
      "step": 570
    },
    {
      "epoch": 0.9442409442409443,
      "grad_norm": 0.9664865136146545,
      "learning_rate": 2.7627118644067794e-05,
      "loss": 0.6095,
      "step": 580
    },
    {
      "epoch": 0.9605209605209605,
      "grad_norm": 0.9015458822250366,
      "learning_rate": 2.7203389830508474e-05,
      "loss": 0.6026,
      "step": 590
    },
    {
      "epoch": 0.9768009768009768,
      "grad_norm": 0.8975563049316406,
      "learning_rate": 2.6779661016949153e-05,
      "loss": 0.6092,
      "step": 600
    },
    {
      "epoch": 0.9930809930809931,
      "grad_norm": 0.9935470223426819,
      "learning_rate": 2.6355932203389833e-05,
      "loss": 0.6347,
      "step": 610
    }
  ],
  "logging_steps": 10,
  "max_steps": 1230,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5290111753076736.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
